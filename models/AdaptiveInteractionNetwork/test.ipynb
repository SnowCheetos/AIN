{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9234feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9693c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 41009250.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 28881/28881 [00:00<00:00, 20853106.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 28613890.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 4542/4542 [00:00<00:00, 11407502.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "x_train, y_train = (training_data.data.float()/255).reshape(-1, 28*28), training_data.targets.long()\n",
    "x_test, y_test = (test_data.data.float()/255).reshape(-1, 28*28).to(device), test_data.targets.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8d0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "limits = 3200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a6ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AIN import Adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca9aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Adaptive(28 * 28, 50, loops=1, directional=\"random\", selfLoops=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e935567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/10 | TEST LOSS: 1.12186 | TEST ACCY: 0.67360 | TEST PREC: 0.70183\n",
      "EPOCH: 2/10 | TEST LOSS: 0.72535 | TEST ACCY: 0.80930 | TEST PREC: 0.81742\n",
      "EPOCH: 3/10 | TEST LOSS: 0.67104 | TEST ACCY: 0.83940 | TEST PREC: 0.84753\n",
      "EPOCH: 4/10 | TEST LOSS: 0.64712 | TEST ACCY: 0.85140 | TEST PREC: 0.85501\n",
      "EPOCH: 5/10 | TEST LOSS: 0.60982 | TEST ACCY: 0.86860 | TEST PREC: 0.87202\n",
      "EPOCH: 6/10 | TEST LOSS: 0.61522 | TEST ACCY: 0.87770 | TEST PREC: 0.87958\n",
      "EPOCH: 7/10 | TEST LOSS: 0.65126 | TEST ACCY: 0.87550 | TEST PREC: 0.87773\n",
      "EPOCH: 8/10 | TEST LOSS: 0.69307 | TEST ACCY: 0.87060 | TEST PREC: 0.87437\n",
      "EPOCH: 9/10 | TEST LOSS: 0.70646 | TEST ACCY: 0.88510 | TEST PREC: 0.88873\n",
      "EPOCH: 10/10 | TEST LOSS: 0.72217 | TEST ACCY: 0.87940 | TEST PREC: 0.88243\n"
     ]
    }
   ],
   "source": [
    "# model = StandardNN(28*28, 100, 10).to(device) \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "logs = {\n",
    "    \"training loss\": [],\n",
    "    \"testing loss\": [],\n",
    "    \"testing accuracy\": [],\n",
    "    \"testing precision\": [],\n",
    "    \"graph edges\": []\n",
    "}\n",
    "\n",
    "x_train = x_train[:limits]\n",
    "y_train = y_train[:limits]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    for i in range(0, x_train.shape[0]//batch_size):\n",
    "        batch_num = i * batch_size\n",
    "        x, y = x_train[batch_num:batch_num+batch_size], y_train[batch_num:batch_num+batch_size]\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        print(f\"EPOCH: {epoch+1}/{epochs} | BATCH: {i+1}/{x_train.shape[0]//batch_size} | LOSS: {running_loss / (i+1):.5f}\", end=\"\\r\", flush=True)\n",
    "    logs[\"training loss\"].append(running_loss/(x_train.shape[0]//batch_size))\n",
    "    model.eval()\n",
    "    test_pred = model(x_test)\n",
    "    loss_te = loss_fn(test_pred, y_test)\n",
    "    test_pred = test_pred.detach().cpu().numpy().argmax(1)\n",
    "    accy = accuracy_score(test_pred, y_test.detach().cpu().numpy())\n",
    "    prec = precision_score(test_pred, y_test.detach().cpu().numpy(), average=\"weighted\")\n",
    "    print(f\"EPOCH: {epoch+1}/{epochs} | TEST LOSS: {loss_te.item():.5f} | TEST ACCY: {accy:.5f} | TEST PREC: {prec:.5f}\")#\" | CONNECTIONS: {model.get_connection_count()}\")\n",
    "    logs[\"testing loss\"].append(loss_te.item())\n",
    "    logs[\"testing accuracy\"].append(accy)\n",
    "    logs[\"testing precision\"].append(prec)\n",
    "    #logs[\"graph edges\"].append(model.get_connection_count())\n",
    "    # model.gen_nx(f\"vis_graph/{epoch+1}.png\")\n",
    "    running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a0afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import adaptiveThresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e7773ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportGraph(model) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Exports a graph from a given model, where nodes represent the model's neurons and edges represent the connections between them.\n",
    "\n",
    "    Args:\n",
    "        model (AIN_Base): An instance of the AIN_Base class.\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: A NetworkX graph object representing the model's graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the node weights and adjacency matrix to numpy arrays on the CPU\n",
    "    nodeWeights = model.nodeWeights.detach().cpu().numpy()\n",
    "    adjacencyMat = adaptiveThresholding(model.adjacencyMat).detach().cpu().numpy()\n",
    "\n",
    "    # Create a networkx graph object based on the specified graph directionality\n",
    "    if model.directional == \"bi\":\n",
    "        # For a bidirectional graph, the adjacency matrix is made symmetric\n",
    "        # and an undirected graph is created\n",
    "        adjacencyMat = np.triu(adjacencyMat) + np.triu(adjacencyMat).T\n",
    "        graph = nx.Graph()\n",
    "    elif model.directional == \"random\":\n",
    "        # For a randomly directed graph, a directed graph is created\n",
    "        graph = nx.DiGraph()\n",
    "    elif model.directional == \"uni\":\n",
    "        # For a unidirectional graph, only the upper triangle of the\n",
    "        # adjacency matrix is used, and a directed graph is created\n",
    "        adjacencyMat = np.triu(adjacencyMat)\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "    # Get the indices and weights of the non-zero elements of the adjacency matrix\n",
    "    edges = np.where(adjacencyMat > 0)\n",
    "    edgeWeights = adjacencyMat[edges[0], edges[1]]\n",
    "\n",
    "    # Normalize the edge weights and combine the indices and weights into a single array\n",
    "    edgeWeightsNorm = edgeWeights / edgeWeights.max()\n",
    "    weightedEdge = tuple(np.concatenate([\n",
    "        edges[0].reshape(-1, 1), \n",
    "        edges[1].reshape(-1, 1),\n",
    "        edgeWeightsNorm.reshape(-1, 1)\n",
    "    ], 1))\n",
    "\n",
    "    # Add the weighted edges to the graph and update node weights\n",
    "    graph.add_weighted_edges_from(weightedEdge, weight=\"edge weight\")\n",
    "    for i, w in enumerate(nodeWeights):\n",
    "        graph.nodes[i].update({\"node weight\": w})\n",
    "\n",
    "    # Return the final graph\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "432be644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countConnections(model) -> int:\n",
    "    nodeWeights = model.nodeWeights.detach().cpu().numpy()\n",
    "    adjacencyMat = adaptiveThresholding(model.adjacencyMat).detach().cpu().numpy()\n",
    "\n",
    "    if model.directional == \"bi\":\n",
    "        adjacencyMat = np.triu(adjacencyMat) + np.triu(adjacencyMat).T\n",
    "    elif model.directional == \"uni\":\n",
    "        adjacencyMat = np.triu(adjacencyMat)\n",
    "\n",
    "    return np.where(adjacencyMat > 0)[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a061770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = None\n",
    "for m in model.children():\n",
    "    if type(m) == Adaptive:\n",
    "        g = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07da95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296852"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countConnections(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39f725b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ImagePositionalEncoding(nn.Module):\n",
    "    def __init__(self, height: int, width: int, channels: int):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.pos_encoding = self.generate_positional_encoding()\n",
    "\n",
    "    def generate_positional_encoding(self):\n",
    "        def angle(h, w, c):\n",
    "            return (h + w) / np.power(10000, (2 * (c // 2)) / self.channels)\n",
    "\n",
    "        pos_encoding = np.fromfunction(angle, (self.height, self.width, self.channels), dtype=np.float32)\n",
    "        pos_encoding[0::2] = np.sin(pos_encoding[0::2])\n",
    "        pos_encoding[1::2] = np.cos(pos_encoding[1::2])\n",
    "\n",
    "        return torch.tensor(pos_encoding, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + self.pos_encoding.to(x.device)\n",
    "\n",
    "\n",
    "class OneDimensionalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, sequence_length: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = self.generate_positional_encoding()\n",
    "\n",
    "    def generate_positional_encoding(self):\n",
    "        def angle(pos, i):\n",
    "            return pos / np.power(10000, (2 * (i // 2)) / self.d_model)\n",
    "\n",
    "        pos_encoding = np.fromfunction(angle, (self.sequence_length, self.d_model), dtype=np.float32)\n",
    "        pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "\n",
    "        return torch.tensor(pos_encoding, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + self.pos_encoding.to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f343f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, height: int, width: int, channels: int) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a 2D positional encoding layer.\n",
    "\n",
    "        Args:\n",
    "        - height (int): The height of the input image.\n",
    "        - width (int): The width of the input image.\n",
    "        - channels (int): The number of channels in the input image.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.pos_encoding = self.generate_positional_encoding()\n",
    "\n",
    "    def generate_positional_encoding(self):\n",
    "        \"\"\"\n",
    "        Generates the positional encoding matrix.\n",
    "\n",
    "        Args:\n",
    "        - None\n",
    "\n",
    "        Returns:\n",
    "        - pos_encoding (Tensor): The positional encoding matrix with shape (1, height, width, channels).\n",
    "        \"\"\"\n",
    "        # Function to compute the angle for positional encoding\n",
    "        def angle(h, w, c):\n",
    "            return (h + w) / np.power(10000, (2 * (c // 2)) / self.channels)\n",
    "\n",
    "        # Create the positional encoding matrix using the angle function\n",
    "        pos_encoding = np.fromfunction(angle, (self.height, self.width, self.channels), dtype=np.float32)\n",
    "        pos_encoding[0::2] = np.sin(pos_encoding[0::2])\n",
    "        pos_encoding[1::2] = np.cos(pos_encoding[1::2])\n",
    "\n",
    "        # Convert the positional encoding matrix to a PyTorch tensor and add a batch dimension\n",
    "        return torch.tensor(pos_encoding, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the output of the 2D positional encoding layer.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): The input tensor with shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: The output tensor with shape (batch_size, channels, height, width).\n",
    "        \"\"\"\n",
    "        # Add the positional encoding to the input tensor and return the result\n",
    "        x = x.permute(0, 2, 3, 1)  # Change the input tensor shape to (batch, height, width, channels)\n",
    "        x = x + self.pos_encoding.to(x.device)\n",
    "        x = x.permute(0, 3, 1, 2)  # Change the output tensor shape back to (batch, channels, height, width)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33327029",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = PositionalEncoding2D(28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2dfb6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(x_train[:32].reshape(-1, 28, 28).unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4232eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "oned = OneDimensionalPositionalEncoding(28*28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97865c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oned(x_train[:32].unsqueeze(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81677495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
